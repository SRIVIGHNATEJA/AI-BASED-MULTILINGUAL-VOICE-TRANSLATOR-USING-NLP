# AI-Based Multilingual Voice Translator using NLP

ğŸ™ï¸ **Speak in any language â†’ Hear it instantly in another.**

This project delivers a **real-time, offline-first voice-to-voice translation pipeline**. It captures spoken audio in a **source language**, detects and transcribes it, translates it into a **target language (chosen by voice)**, and finally speaks the translated output.

It combines **state-of-the-art models** for Indian & international languages, intelligently routing tasks for maximum accuracy & minimal latency.

---

## âœ¨ Key Highlights

* **Fully Voice-Driven:** No typing needed â€” choose the target language by simply saying its name.
* **Multimodel ASR Routing:** Smartly switches between **OpenAI Whisper** (international) and **AI4Bharat IndicConformer** (Indian languages).
* **High-Quality Many-to-Many Translation:** **Metaâ€™s NLLB-200** provides direct translation across 200+ languages.
* **Natural Speech Output:** Uses **Indic-Parler TTS** for expressive Indian speech & **pyttsx3** for global voices.
* **Performance Profiling:** Phase-wise latency tracking & system-level logging for optimization.
* **Offline-First Design:** Once models are downloaded, works without external APIs.

---

## ğŸ›  Core Technologies

* **ASR (Speech Recognition):**

  * **Whisper** â€“ Robust multilingual language detection + transcription
  * **IndicConformer** â€“ Specialized Indian language ASR
* **Translation:** **NLLB-200** â€“ Many-to-many multilingual translation
* **TTS (Speech Synthesis):**

  * **Indic-Parler TTS** â€“ High-quality Indian voices
  * **pyttsx3** â€“ Cross-platform fallback TTS
* **Frameworks:** Hugging Face Transformers, PyTorch, Sounddevice, Scipy

---

## ğŸ“œ How It Works

1. **Record Speech:** Capture & pre-process user audio.
2. **Detect Language:** Whisper auto-detects the spoken language.
3. **Transcribe:**

   * Indian languages â†’ **IndicConformer**
   * Others â†’ **Whisper**
4. **Target Language Selection:** Speak the desired language name (fallback: manual input).
5. **Translate:** **NLLB-200** translates from source â†’ target language.
6. **Speech Synthesis:**

   * Indian output â†’ **Indic-Parler TTS**
   * Other languages â†’ **pyttsx3** fallback.
7. **Log & Profile:** Store phase-wise latencies & system stats in `asr_evaluation_log.json`.

---

## âš¡ Quick Start

```bash
# 1. Clone this repository
git clone <repo-url>
cd AI-Voice-Translator

# 2. Install system dependencies
# macOS:
brew install ffmpeg portaudio
# Ubuntu/Debian:
sudo apt-get update && sudo apt-get install ffmpeg libportaudio2

# 3. Install Python packages
pip install -r requirements.txt

# 4. Run the pipeline
python main.py
```

---

## ğŸ™ï¸ Usage

1. Script plays a **beep** â†’ Speak a sentence in any language.
2. **Second beep** â†’ Speak the **target language name** (e.g., â€œEnglishâ€).
3. Listen to the **translated speech output**.
4. Review **detailed logs** in `asr_evaluation_log.json`.

---

## ğŸ“Š Example Output

```
ğŸ” Latency Report:
 â€¢ record              : 4.39 sec
 â€¢ lang_detect         : 3.23 sec
 â€¢ asr                 : 1.83 sec
 â€¢ target_lang_select  : 7.88 sec
 â€¢ translation         : 12.39 sec
 â€¢ tts                 : 3.44 sec
 â€¢ Total Runtime       : 35.87 sec

ğŸ§¾ Routing:
 â€¢ Source Language     : Telugu (te)
 â€¢ Target Language     : English (en)
 â€¢ Model Routed        : IndicConformer

ğŸ§  Text:
 â€¢ ASR Output          : à°ˆ à°°à±‹à°œà± à°šà°¾à°²à°¾ à°®à°‚à°šà°¿ à°°à±‹à°œà± à°¨à°¾à°•à± à°šà°¾à°²à°¾ à°¸à°‚à°¤à±‹à°·à°‚à°—à°¾ à°‰à°‚à°¦à°¿
 â€¢ Translation Output  : Today is a very good day. I am very happy.
```

---

## ğŸ”® Future Enhancements

* Web-based UI for broader accessibility
* GPU acceleration & model quantization for faster processing
* Multi-speaker diarization & conversation translation
* Translation caching for frequent inputs

---

## ğŸ“œ License

Apache License 2.0
