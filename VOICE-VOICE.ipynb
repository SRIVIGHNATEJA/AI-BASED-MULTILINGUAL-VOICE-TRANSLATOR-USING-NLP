{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "000b1bea",
   "metadata": {},
   "source": [
    "üîÅ PHASE: Unified Real-Time ASR (Whisper + IndicConformer Integration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d07baa",
   "metadata": {},
   "source": [
    "‚úÖ Cell 1 ‚Äì Install & Setup\n",
    "\n",
    "Unified Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac40d8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flash attention 2 is not installed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading Whisper model...\n",
      "üîÅ Loading IndicConformer model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/ai4bharat/indic-conformer-600m-multilingual:\n",
      "- model_onnx.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e873bc8338c400d8068f32a5f67e815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 403 files:   0%|          | 0/403 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696dfde8b5e648999772e574f867f559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading NLLB-200 model...\n",
      "üîÅ Loading Indic-Parler TTS model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the text_encoder: <class 'transformers.models.t5.modeling_t5.T5EncoderModel'> is overwritten by shared text_encoder config: T5Config {\n",
      "  \"_name_or_path\": \"google/flan-t5-large\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2816,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 24,\n",
      "  \"num_heads\": 16,\n",
      "  \"num_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Config of the audio_encoder: <class 'transformers.models.dac.modeling_dac.DacModel'> is overwritten by shared audio_encoder config: DacConfig {\n",
      "  \"_name_or_path\": \"ylacombe/dac_44khz\",\n",
      "  \"architectures\": [\n",
      "    \"DacModel\"\n",
      "  ],\n",
      "  \"codebook_dim\": 8,\n",
      "  \"codebook_loss_weight\": 1.0,\n",
      "  \"codebook_size\": 1024,\n",
      "  \"commitment_loss_weight\": 0.25,\n",
      "  \"decoder_hidden_size\": 1536,\n",
      "  \"downsampling_ratios\": [\n",
      "    2,\n",
      "    4,\n",
      "    8,\n",
      "    8\n",
      "  ],\n",
      "  \"encoder_hidden_size\": 64,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"hop_length\": 512,\n",
      "  \"model_type\": \"dac\",\n",
      "  \"n_codebooks\": 9,\n",
      "  \"quantizer_dropout\": 0.0,\n",
      "  \"sampling_rate\": 44100,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    8,\n",
      "    4,\n",
      "    2\n",
      "  ]\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'parler_tts.modeling_parler_tts.ParlerTTSForCausalLM'> is overwritten by shared decoder config: ParlerTTSDecoderConfig {\n",
      "  \"_name_or_path\": \"/fsx/yoach/tmp/artefacts/parler-tts-mini-v2-empty/decoder\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"ParlerTTSForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1025,\n",
      "  \"codebook_weights\": null,\n",
      "  \"cross_attention_implementation_strategy\": null,\n",
      "  \"delay_strategy\": \"delay\",\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 1024,\n",
      "  \"ffn_dim\": 4096,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_factor\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layerdrop\": 0.0,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"parler_tts_decoder\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codebooks\": 9,\n",
      "  \"num_cross_attention_key_value_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 1024,\n",
      "  \"rope_embeddings\": false,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"scale_embedding\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.46.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_fused_lm_heads\": true,\n",
      "  \"vocab_size\": 1088\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading tokenizers...\n",
      "üîÅ Initializing fallback TTS engine...\n",
      "‚úÖ All models loaded successfully (and Indic-Parler is warmed up).\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CELL: Tuned IndicParler TTS Loading ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "\n",
    "# üîß Device Setup\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"üî• Using device: {device.upper()}\")\n",
    "\n",
    "# üì¶ Core Libraries\n",
    "import whisper\n",
    "import pyttsx3\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import platform\n",
    "import psutil\n",
    "import datetime\n",
    "import time\n",
    "from difflib import get_close_matches\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from parler_tts import ParlerTTSForConditionalGeneration\n",
    "import torchaudio\n",
    "from playsound import playsound\n",
    "\n",
    "# üé§ Whisper ASR (English + Intl.)\n",
    "print(\"üîÅ Loading Whisper model...\")\n",
    "whisper_model = whisper.load_model(\"small\").to(device)\n",
    "whisper_model.eval()\n",
    "\n",
    "# ü™∑ IndicConformer (Indian ASR)\n",
    "print(\"üîÅ Loading IndicConformer model...\")\n",
    "indic_model = AutoModel.from_pretrained(\n",
    "    \"ai4bharat/indic-conformer-600m-multilingual\",\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "indic_model.eval()\n",
    "\n",
    "# üåê NLLB Translation Pipeline (200+ languages)\n",
    "print(\"üîÅ Loading NLLB-200 model...\")\n",
    "nllb_pipeline = pipeline(\n",
    "    \"translation\",\n",
    "    model=\"facebook/nllb-200-distilled-600M\",\n",
    "    device=0 if device == \"cuda\" else -1\n",
    ")\n",
    "\n",
    "# üß† Parler-TTS Model & Tokenizers (Tuned)\n",
    "print(\"üîÅ Loading Indic-Parler TTS model...\")\n",
    "# 1) Load the exact HF model:\n",
    "model = ParlerTTSForConditionalGeneration.from_pretrained(\n",
    "    \"ai4bharat/indic-parler-tts\"\n",
    ").to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"üîÅ Loading tokenizers...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-parler-tts\")\n",
    "description_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model.config.text_encoder._name_or_path\n",
    ")\n",
    "\n",
    "# 2) Ensure pad_token is set correctly:\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "if description_tokenizer.pad_token is None:\n",
    "    description_tokenizer.pad_token = description_tokenizer.eos_token\n",
    "\n",
    "# üîä pyttsx3 TTS (Fallback + Intl. Language Speech)\n",
    "print(\"üîÅ Initializing fallback TTS engine...\")\n",
    "engine = pyttsx3.init()\n",
    "engine.setProperty(\"rate\", 200)\n",
    "engine.setProperty(\"volume\", 1.0)\n",
    "\n",
    "# ‚úÖ Confirmation\n",
    "print(\"‚úÖ All models loaded successfully (and Indic-Parler is warmed up).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5568ca0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRun once Use as many times as you want'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Run once Use as many times as you want'''\n",
    "#%pip install git+https://github.com/openai/whisper.git -q\n",
    "#%pip install sounddevice scipy torchaudio transformers -q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb60451",
   "metadata": {},
   "source": [
    "‚úÖ Cell 4 ‚Äì Language Detection & Routing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81758759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìú Master list of Indian language codes for special routing\n",
    "indian_languages = {\n",
    "    \"as\": \"Assamese\", \"bn\": \"Bengali\", \"brx\": \"Bodo\", \"doi\": \"Dogri\", \"gu\": \"Gujarati\",\n",
    "    \"hi\": \"Hindi\", \"kn\": \"Kannada\", \"kok\": \"Konkani\", \"ks\": \"Kashmiri\", \"mai\": \"Maithili\",\n",
    "    \"ml\": \"Malayalam\", \"mni\": \"Manipuri\", \"mr\": \"Marathi\", \"ne\": \"Nepali\", \"or\": \"Odia\",\n",
    "    \"pa\": \"Punjabi\", \"sa\": \"Sanskrit\", \"sat\": \"Santali\", \"sd\": \"Sindhi\", \"ta\": \"Tamil\",\n",
    "    \"te\": \"Telugu\", \"ur\": \"Urdu\"\n",
    "}\n",
    "\n",
    "def detect_input_language_whisper(audio_path: str, model=None):\n",
    "    \"\"\"\n",
    "    Detects language from an audio file using Whisper's detect_language.\n",
    "    Returns language code, name, and whether it's Indian.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        raise ValueError(\"Whisper model must be provided.\")\n",
    "    \n",
    "    audio = whisper.load_audio(audio_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    _, probs = model.detect_language(mel)\n",
    "    detected_code = max(probs, key=probs.get)\n",
    "    is_indian = detected_code in indian_languages\n",
    "    lang_name = indian_languages.get(detected_code, \"International\")\n",
    "\n",
    "    print(f\"üåê Detected Language Code: {detected_code}\")\n",
    "    print(f\"üåê Interpreted as: {lang_name}\")\n",
    "\n",
    "    return detected_code, lang_name, is_indian\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af65be9",
   "metadata": {},
   "source": [
    "‚úÖ Cell 5 ‚Äì IndicConformer or Whisper Transcription\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8658ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_path: str, whisper_model):\n",
    "    \"\"\"\n",
    "    Transcribes audio using IndicConformer if Indian language is detected,\n",
    "    else falls back to Whisper.\n",
    "    \"\"\"\n",
    "    # üåê Detect language using our modular Cell 4 function\n",
    "    lang_code, lang_name, is_indic = detect_input_language_whisper(audio_path, whisper_model)\n",
    "\n",
    "    if is_indic:\n",
    "        print(f\"üõ§Ô∏è Routing to IndicConformer for {lang_name}...\")\n",
    "        try:\n",
    "            # Load audio\n",
    "            audio_tensor, sr = torchaudio.load(audio_path)\n",
    "            if sr != 16000:\n",
    "                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
    "                audio_tensor = resampler(audio_tensor)\n",
    "            audio_tensor = torch.mean(audio_tensor, dim=0, keepdim=True)\n",
    "\n",
    "            # Load IndicConformer (would ideally cache globally)\n",
    "            # indic_model = AutoModel.from_pretrained(\"ai4bharat/indic-conformer-600m-multilingual\", trust_remote_code=True)\n",
    "            #Already loaded in cell 2\n",
    "            # Perform ASR (placeholder ‚Äì actual method call will depend on interface)\n",
    "            transcription = indic_model(audio_tensor, lang_code, \"ctc\")  # Replace with real inference call\n",
    "            print(f\"üìù IndicConformer Transcription: {transcription}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è IndicConformer failed: {e}\")\n",
    "            print(f\"üîÅ Falling back to Whisper...\")\n",
    "            transcription = whisper_transcribe(audio_path, whisper_model)\n",
    "            print(f\"üìù Whisper Transcription: {transcription}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"üõ§Ô∏è International language detected. Using Whisper...\")\n",
    "        transcription = whisper_transcribe(audio_path, whisper_model)\n",
    "        print(f\"üìù Whisper Transcription: {transcription}\")\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "\n",
    "\n",
    "def whisper_transcribe(audio_path: str, model):\n",
    "    \"\"\"\n",
    "    Whisper fallback transcription logic.\n",
    "    \"\"\"\n",
    "    audio = whisper.load_audio(audio_path)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    options = whisper.DecodingOptions()\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad8e05d",
   "metadata": {},
   "source": [
    "PHASE-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa0875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî§ Supported language mapping\n",
    "supported_languages = {\n",
    "    \"english\": \"en\", \"hindi\": \"hi\", \"telugu\": \"te\", \"tamil\": \"ta\", \"german\": \"de\",\n",
    "    \"french\": \"fr\", \"bengali\": \"bn\", \"marathi\": \"mr\", \"kannada\": \"kn\", \"malayalam\": \"ml\",\n",
    "    \"japanese\": \"ja\", \"spanish\": \"es\", \"gujarati\": \"gu\", \"punjabi\": \"pa\"\n",
    "}\n",
    "\n",
    "def get_language_code(spoken_input: str):\n",
    "    \"\"\"\n",
    "    Matches spoken input to a known language.\n",
    "    Returns (code, language_name) if matched, else (None, None)\n",
    "    \"\"\"\n",
    "    spoken_input = spoken_input.lower().strip()\n",
    "    close_match = get_close_matches(spoken_input, supported_languages.keys(), n=1, cutoff=0.4)\n",
    "    if close_match:\n",
    "        matched_lang = close_match[0]\n",
    "        print(f\"‚úÖ Interpreted as: {matched_lang.capitalize()}\")\n",
    "        return supported_languages[matched_lang], matched_lang\n",
    "    else:\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e41444",
   "metadata": {},
   "source": [
    "‚úÖ Cell 7 ‚Äì Recording Utility (Reusable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ea644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    # üõ° Ensure highcut doesn't reach Nyquist\n",
    "    if highcut >= nyq:\n",
    "        highcut = nyq - 1\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    return butter(order, [low, high], btype='band')\n",
    "\n",
    "def bandpass_filter(data, lowcut=80.0, highcut=7900.0, fs=16000, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "\n",
    "def record_audio(duration=3, fs=16000, filename=\"user_input.wav\", playback=False):\n",
    "    \"\"\"\n",
    "    Records 'duration' seconds of audio, applies gentle bandpass filter\n",
    "    to remove noise, and saves to 'filename'.\n",
    "    \"\"\"\n",
    "    print(f\"üé§ Recording ({duration}s)‚Ä¶\")\n",
    "    data = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype=\"float32\")\n",
    "    sd.wait()\n",
    "    raw = data.flatten()\n",
    "\n",
    "    # üîá Apply bandpass filter (removes <80 Hz hum, >8kHz hiss)\n",
    "    filtered = bandpass_filter(raw, lowcut=80.0, highcut=8000.0, fs=fs)\n",
    "\n",
    "    if playback:\n",
    "        print(\"üîä Playing back filtered audio‚Ä¶\")\n",
    "        sd.play(filtered, fs)\n",
    "        sd.wait()\n",
    "\n",
    "    # Save to file\n",
    "    sf.write(filename, filtered, fs)\n",
    "    print(f\"‚úÖ Filtered audio saved: {filename}\")\n",
    "    return filename\n",
    "\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bffc3",
   "metadata": {},
   "source": [
    "‚úÖ Cell 8 ‚Äì Voice-Based Target Language Detection Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d918fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_target_language_by_voice(attempts=2):\n",
    "    \"\"\"\n",
    "    Prompts user to speak the target language name.\n",
    "    Returns language_code, language_name if matched, else (None, None)\n",
    "    \"\"\"\n",
    "    for attempt in range(attempts):\n",
    "        print(f\"üó£Ô∏è Attempt {attempt + 1}/{attempts}: Speak target language name (e.g., Tamil, Hindi, German)\")\n",
    "        file_path = record_audio(duration=1.7, filename=f\"target_attempt_{attempt + 1}.wav\")\n",
    "        \n",
    "        audio = whisper.load_audio(file_path)\n",
    "        audio = whisper.pad_or_trim(audio)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(whisper_model.device)\n",
    "\n",
    "        result = whisper.decode(whisper_model, mel)\n",
    "        spoken = result.text.strip()\n",
    "        print(f\"üìù You said: {spoken}\")\n",
    "\n",
    "        lang_code, lang_name = get_language_code(spoken)\n",
    "        if lang_code:\n",
    "            return lang_code, lang_name\n",
    "        \n",
    "        print(\"‚ö†Ô∏è Not confident. Try again...\\n\")\n",
    "\n",
    "    return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2590a6",
   "metadata": {},
   "source": [
    "‚úÖ Cell 9 ‚Äì Manual Fallback for Language Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d12ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_target_language_manually():\n",
    "    print(\"üî° Please type the target language name (e.g., English, Hindi):\")\n",
    "    typed_input = input(\"Your input: \").strip().lower()\n",
    "    lang_code, lang_name = get_language_code(typed_input)\n",
    "    \n",
    "    if lang_code:\n",
    "        return lang_code, lang_name\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Not recognized. Suggestions:\")\n",
    "        matches = get_close_matches(typed_input, supported_languages.keys(), n=3)\n",
    "        print(\"üîé Close matches:\", \", \".join(matches))\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d305d07",
   "metadata": {},
   "source": [
    "‚úÖ Cell 10 ‚Äì Combined Driver Function for Target Language Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8d97b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_language():\n",
    "    print(\"üéØ Target Language Selection Started\")\n",
    "    code, name = detect_target_language_by_voice()\n",
    "    if not code:\n",
    "        print(\"üîÅ Switching to manual input...\")\n",
    "        code, name = detect_target_language_manually()\n",
    "    \n",
    "    if code:\n",
    "        print(f\"‚úÖ Final Target Language: {name.capitalize()} ({code})\")\n",
    "    else:\n",
    "        print(\"‚ùå Language not supported. Cannot continue without valid target.\")\n",
    "    \n",
    "    return code, name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8642f61",
   "metadata": {},
   "source": [
    "‚úÖ Phase-03: Unified Translation Pipeline (NLLB Only)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8e5a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified NLLB language codes\n",
    "NLLB_LANG_CODE_MAP = {\n",
    "    'en': 'eng_Latn', 'hi': 'hin_Deva', 'te': 'tel_Telu', 'ta': 'tam_Taml',\n",
    "    'bn': 'ben_Beng', 'ml': 'mal_Mlym', 'kn': 'kan_Knda', 'mr': 'mar_Deva',\n",
    "    'gu': 'guj_Gujr', 'pa': 'pan_Guru', 'ur': 'urd_Arab', 'ne': 'npi_Deva',\n",
    "    'or': 'ory_Orya', 'as': 'asm_Beng', 'sd': 'snd_Arab', 'si': 'sin_Sinh',\n",
    "    'fr': 'fra_Latn', 'de': 'deu_Latn', 'es': 'spa_Latn', 'zh': 'zho_Hans',\n",
    "    'ja': 'jpn_Jpan', 'ko': 'kor_Hang', 'ru': 'rus_Cyrl', 'ar': 'arb_Arab',\n",
    "    'pt': 'por_Latn', 'it': 'ita_Latn'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a037c",
   "metadata": {},
   "source": [
    "üîÅ NLLB Translation Function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a50cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_with_nllb(text, src_lang_code, tgt_lang_code):\n",
    "    \"\"\"\n",
    "    Translates given text using NLLB model from source to target language.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src_nllb = NLLB_LANG_CODE_MAP.get(src_lang_code, \"eng_Latn\")\n",
    "        tgt_nllb = NLLB_LANG_CODE_MAP.get(tgt_lang_code, \"eng_Latn\")\n",
    "        \n",
    "        translated = nllb_pipeline(text, src_lang=src_nllb, tgt_lang=tgt_nllb, max_length=512)\n",
    "        return translated[0]['translation_text']\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Translation failed: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9853d0",
   "metadata": {},
   "source": [
    "üîÑ Route Handler: Connect Phase-1 ‚Üí Phase-2 ‚Üí Phase-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "170d7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_translation_pipeline(transcribed_text, detected_lang_code, target_lang_code=\"en\"):\n",
    "    \"\"\"\n",
    "    Routes transcribed audio (from Whisper/IndicASR) and detected lang (FastText)\n",
    "    through NLLB for translation.\n",
    "    \"\"\"\n",
    "    print(f\"\\n[INFO] Source Language Detected: {detected_lang_code}\")\n",
    "    print(f\"[INFO] Translating to Target Language: {target_lang_code}\")\n",
    "\n",
    "    translated_text = translate_with_nllb(transcribed_text, detected_lang_code, target_lang_code)\n",
    "    if translated_text:\n",
    "        print(f\"[SUCCESS] Translation Output:\\n{translated_text}\")\n",
    "    else:\n",
    "        print(\"[FAILURE] No translated output.\")\n",
    "    return translated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35371e03",
   "metadata": {},
   "source": [
    "üîß Phase 4: Advanced Usage and Optimization of Indic Parler-TTS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3f5e9",
   "metadata": {},
   "source": [
    "1. Installation and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cedb08c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun once Use as many times as you want\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "run once Use as many times as you want\n",
    "''' \n",
    "#%pip install git+https://github.com/huggingface/parler-tts.git\n",
    "#%pip install transformers soundfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1550f3da",
   "metadata": {},
   "source": [
    "3. Generating Speech with Custom Descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3eaf4959",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_speech(prompt, description, output_file=\"output.wav\"):\n",
    "    \"\"\"\n",
    "    Generate clean TTS audio using Indic-Parler and validate the waveform.\n",
    "    \"\"\"\n",
    "    if not prompt.strip() or not description.strip():\n",
    "        print(\"üö´ Empty prompt or description. Skipping TTS.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Tokenize\n",
    "        desc_inputs = description_tokenizer(description, return_tensors=\"pt\", padding=True).to(device)\n",
    "        prompt_inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "        # Generate\n",
    "        with torch.no_grad():\n",
    "            generation = model.generate(\n",
    "                input_ids=desc_inputs.input_ids,\n",
    "                attention_mask=desc_inputs.attention_mask,\n",
    "                prompt_input_ids=prompt_inputs.input_ids,\n",
    "                prompt_attention_mask=prompt_inputs.attention_mask,\n",
    "                max_length=512,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "        audio_arr = generation.cpu().numpy().squeeze()\n",
    "\n",
    "        # Validate waveform\n",
    "        if audio_arr.size == 0 or np.all(audio_arr == 0) or np.isnan(audio_arr).any():\n",
    "            print(\"‚ùå Generated audio is invalid or silent. Skipping playback.\")\n",
    "            return\n",
    "\n",
    "        # Save with correct sampling rate\n",
    "        sf.write(output_file, audio_arr, model.config.sampling_rate)\n",
    "        print(f\"‚úÖ Audio saved: {output_file}\")\n",
    "        playsound(output_file)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"üî• Error in TTS generation: {e}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87322a2c",
   "metadata": {},
   "source": [
    "‚úÖ Notebook Cells (Phase 5: TTS Routing & Playback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5602f90",
   "metadata": {},
   "source": [
    "*üîß Cell 1: Install & Import Required Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "927192a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indian language codes\n",
    "INDIAN_LANGS = set([\n",
    "    'hi', 'te', 'ta', 'bn', 'ml', 'kn', 'mr', 'gu', 'pa', 'ur', 'ne', 'or', 'as', 'sd', 'si'\n",
    "])\n",
    "\n",
    "def nllb_translate_and_classify(text, src_lang_code, tgt_lang_code):\n",
    "    try:\n",
    "        src_nllb = NLLB_LANG_CODE_MAP.get(src_lang_code, 'eng_Latn')\n",
    "        tgt_nllb = NLLB_LANG_CODE_MAP.get(tgt_lang_code, 'eng_Latn')\n",
    "\n",
    "        translated = nllb_pipeline(text, src_lang=src_nllb, tgt_lang=tgt_nllb, max_length=512)\n",
    "        translated_text = translated[0]['translation_text']\n",
    "\n",
    "        lang_type = 'indian' if tgt_lang_code in INDIAN_LANGS else 'international'\n",
    "        return translated_text, tgt_lang_code, lang_type\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] NLLB Translation Failed: {e}\")\n",
    "        return None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "866ca194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# International language voices (macOS Voice IDs)\n",
    "LANG_VOICE_MAP = {\n",
    "    \"en\": \"com.apple.voice.compact.en-US.Samantha\",\n",
    "    \"es\": \"com.apple.voice.compact.es-ES.Monica\",\n",
    "    \"fr\": \"com.apple.voice.compact.fr-FR.Thomas\",\n",
    "    \"zh\": \"com.apple.voice.compact.zh-CN.Tingting\",\n",
    "    \"ar\": \"com.apple.voice.compact.ar-001.Maged\",\n",
    "    \"pt\": \"com.apple.voice.compact.pt-BR.Luciana\",\n",
    "    \"ru\": \"com.apple.voice.compact.ru-RU.Milena\",\n",
    "    \"ja\": \"com.apple.voice.compact.ja-JP.Kyoko\",\n",
    "    \"de\": \"com.apple.voice.compact.de-DE.Anna\"\n",
    "}\n",
    "\n",
    "# Unified TTS Playback\n",
    "def play_tts_output(text, lang_type, tgt_lang_code):\n",
    "    if lang_type == \"indian\":\n",
    "        # Indic-Parler TTS\n",
    "        description = \"A calm neutral Indian voice with natural pace and studio quality.\"\n",
    "        desc_inputs = description_tokenizer(description, return_tensors=\"pt\").to(device)\n",
    "        prompt_inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            generation = model.generate(\n",
    "                input_ids=desc_inputs.input_ids,\n",
    "                attention_mask=desc_inputs.attention_mask,\n",
    "                prompt_input_ids=prompt_inputs.input_ids,\n",
    "                prompt_attention_mask=prompt_inputs.attention_mask\n",
    "                )\n",
    "        audio_arr = generation.cpu().numpy().squeeze()\n",
    "        output_file = \"output_indic.wav\"\n",
    "        sf.write(output_file, audio_arr, samplerate=16000, subtype='PCM_16')\n",
    "        playsound(output_file)\n",
    "        print(f\"‚úÖ Played via IndicParler [{tgt_lang_code}]\")\n",
    "\n",
    "    elif lang_type == \"international\":\n",
    "        voice_id = LANG_VOICE_MAP.get(tgt_lang_code, LANG_VOICE_MAP[\"en\"])\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty(\"voice\", voice_id)\n",
    "        engine.setProperty(\"rate\", 180)\n",
    "        engine.setProperty(\"volume\", 1.0)\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        engine.stop()\n",
    "        print(f\"‚úÖ Played via pyttsx3 [{tgt_lang_code}] voice: {voice_id.split('.')[-1]}\")\n",
    "def play_tts_output(text, lang_type, tgt_lang_code):\n",
    "    \"\"\"\n",
    "    Unified TTS playback.  \n",
    "    For 'indian' ‚Üí use Indic‚ÄêParler TTS, with empty‚Äêwaveform checks.  \n",
    "    For 'international' ‚Üí use pyttsx3 fallback.\n",
    "    \"\"\"\n",
    "    # 1Ô∏è‚É£ Sanity check: skip if text is empty\n",
    "    if not text or not text.strip():\n",
    "        print(\"‚ö†Ô∏è play_tts_output called with empty text. Skipping TTS.\")\n",
    "        return\n",
    "\n",
    "    if lang_type == \"indian\":\n",
    "        # ‚è≥ Generate Indic‚ÄêParler audio\n",
    "        description = \"A calm neutral Indian voice with natural pace and studio quality.\"\n",
    "        desc_inputs = description_tokenizer(description, return_tensors=\"pt\").to(device)\n",
    "        prompt_inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            generation = model.generate(\n",
    "                input_ids=desc_inputs.input_ids,\n",
    "                attention_mask=desc_inputs.attention_mask,\n",
    "                prompt_input_ids=prompt_inputs.input_ids,\n",
    "                prompt_attention_mask=prompt_inputs.attention_mask\n",
    "            )\n",
    "\n",
    "        audio_arr = generation.cpu().numpy().squeeze()\n",
    "        if audio_arr.size == 0 or np.all(audio_arr == 0):\n",
    "            print(\"‚ùå Indic-Parler TTS failed‚Äîempty waveform. Skipping playback.\")\n",
    "            return\n",
    "\n",
    "        output_file = \"output_indic.wav\"\n",
    "        sf.write(output_file, audio_arr, samplerate=16000, subtype='PCM_16')\n",
    "        file_size = os.path.getsize(output_file) if os.path.exists(output_file) else 0\n",
    "        if file_size > 1000:\n",
    "            print(f\"üîä Playing Indic-Parler output: {output_file} (size: {file_size} bytes)\")\n",
    "            playsound(output_file)\n",
    "        else:\n",
    "            print(f\"‚ùå File not valid or too small ({file_size} bytes). Skipping playback.\")\n",
    "\n",
    "        print(f\"‚úÖ Played via IndicParler [{tgt_lang_code}]\")\n",
    "\n",
    "    elif lang_type == \"international\":\n",
    "        # üó£Ô∏è pyttsx3 fallback\n",
    "        voice_id = LANG_VOICE_MAP.get(tgt_lang_code, LANG_VOICE_MAP[\"en\"])\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty(\"voice\", voice_id)\n",
    "        engine.setProperty(\"rate\", 180)\n",
    "        engine.setProperty(\"volume\", 1.0)\n",
    "\n",
    "        print(f\"üîä Playing via pyttsx3 [{tgt_lang_code}] voice: {voice_id.split('.')[-1]}\")\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "        engine.stop()\n",
    "        print(f\"‚úÖ Played via pyttsx3 [{tgt_lang_code}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7579f5",
   "metadata": {},
   "source": [
    "Final Testing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07a00e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO ID                                     REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED     LAST_MODIFIED  REFS             LOCAL PATH                                                                                       \n",
      "------------------------------------------- --------- ------------ -------- ----------------- -------------- ---------------- ------------------------------------------------------------------------------------------------ \n",
      "Helsinki-NLP/opus-mt-en-hi                  model             4.0M        5 4 weeks ago       4 weeks ago    main             /Users/srivighnateja/.cache/huggingface/hub/models--Helsinki-NLP--opus-mt-en-hi                  \n",
      "ai4bharat/indic-conformer-600m-multilingual model             2.6G      404 24 seconds ago    39 seconds ago main             /Users/srivighnateja/.cache/huggingface/hub/models--ai4bharat--indic-conformer-600m-multilingual \n",
      "ai4bharat/indic-parler-tts                  model             3.8G        7 a few seconds ago 2 months ago   main             /Users/srivighnateja/.cache/huggingface/hub/models--ai4bharat--indic-parler-tts                  \n",
      "facebook/nllb-200-distilled-600M            model             4.9G        8 a few seconds ago 2 months ago   main, refs/pr/39 /Users/srivighnateja/.cache/huggingface/hub/models--facebook--nllb-200-distilled-600M            \n",
      "google/flan-t5-large                        model             3.2M        4 6 weeks ago       6 weeks ago    main             /Users/srivighnateja/.cache/huggingface/hub/models--google--flan-t5-large                        \n",
      "\n",
      "Done in 0.0s. Scanned 5 repo(s) for a total of \u001b[1m\u001b[31m11.3G\u001b[0m.\n",
      "\u001b[90mGot 1 warning(s) while scanning. Use -vvv to print details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli scan-cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d631a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# import os\n",
    "\n",
    "# # Define the path of the cached model\n",
    "# model_cache_path = '/Users/srivighnateja/.cache/huggingface/hub/models--google--flan-t5-large'\n",
    "\n",
    "# # Check if the directory exists and delete it\n",
    "# if os.path.exists(model_cache_path):\n",
    "#     shutil.rmtree(model_cache_path)\n",
    "#     print(f\"Deleted model cache at {model_cache_path}\")\n",
    "# else:\n",
    "#     print(f\"Model cache not found at {model_cache_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d5bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_beep(duration=0.07, freq=1000, fs=44100):\n",
    "    \"\"\"\n",
    "    Plays a beep sound of given duration and frequency using sounddevice.\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, duration, int(fs * duration), False)\n",
    "    beep = np.sin(freq * 2 * np.pi * t)\n",
    "    sd.play(beep, fs)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15dd6293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Warming up all models‚Ä¶\n",
      "‚úÖ Whisper warm-up 1/2 in 8.83s\n",
      "‚úÖ Whisper warm-up 2/2 in 5.59s\n",
      "‚úÖ IndicConformer warm-up 1/2 in 6.63s\n",
      "‚úÖ IndicConformer warm-up 2/2 in 0.38s\n",
      "‚úÖ NLLB translation warm-up 1/2 in 19.16s\n",
      "‚úÖ NLLB translation warm-up 2/2 in 13.93s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 1Ô∏è‚É£ Silence the tokenizers fork warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# 2Ô∏è‚É£ Force 8-core CPU for PyTorch\n",
    "torch.set_num_threads(8)\n",
    "\n",
    "print(\"üöÄ Warming up all models‚Ä¶\")\n",
    "\n",
    "# 3Ô∏è‚É£ Create 1s silent audio at 16kHz (if not already created)\n",
    "if not os.path.exists(\"dummy.wav\"):\n",
    "    dummy_audio = np.zeros(16000, dtype=\"float32\")\n",
    "    sf.write(\"dummy.wav\", dummy_audio, 16000)\n",
    "\n",
    "# ‚úÖ Ensure pad_token is set before any TTS warm-up\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "if description_tokenizer.pad_token is None:\n",
    "    description_tokenizer.pad_token = description_tokenizer.eos_token\n",
    "\n",
    "# 4Ô∏è‚É£ Whisper Warm-up\n",
    "try:\n",
    "    for i in range(2):\n",
    "        t0 = time.time()\n",
    "        a = whisper.load_audio(\"dummy.wav\")\n",
    "        a = whisper.pad_or_trim(a)\n",
    "        m = whisper.log_mel_spectrogram(a).to(whisper_model.device)\n",
    "        _ = whisper.decode(whisper_model, m)\n",
    "        t1 = time.time()\n",
    "        print(f\"‚úÖ Whisper warm-up {i+1}/2 in {t1-t0:.2f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Whisper warm-up failed: {e}\")\n",
    "\n",
    "# 5Ô∏è‚É£ IndicConformer Warm-up\n",
    "try:\n",
    "    for i in range(2):\n",
    "        t0 = time.time()\n",
    "        at, sr = torchaudio.load(\"dummy.wav\")\n",
    "        if sr != 16000:\n",
    "            from torchaudio.transforms import Resample\n",
    "            at = Resample(sr, 16000)(at)\n",
    "        inp = at.mean(dim=0, keepdim=True).to(device)\n",
    "        _ = indic_model(inp, \"hi\", \"ctc\")\n",
    "        t1 = time.time()\n",
    "        print(f\"‚úÖ IndicConformer warm-up {i+1}/2 in {t1-t0:.2f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è IndicConformer warm-up failed: {e}\")\n",
    "\n",
    "# 6Ô∏è‚É£ NLLB Translation Warm-up\n",
    "try:\n",
    "    for i in range(2):\n",
    "        t0 = time.time()\n",
    "        _ = nllb_pipeline(\"Hello world\", src_lang=\"eng_Latn\", tgt_lang=\"tel_Telu\")\n",
    "        t1 = time.time()\n",
    "        print(f\"‚úÖ NLLB translation warm-up {i+1}/2 in {t1-t0:.2f}s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è NLLB warm-up failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dccd9130",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`prompt_attention_mask` is specified but `attention_mask` is not. A full `attention_mask` will be created. Make sure this is the intended behaviour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ IndicParlerTTS warm-up 1/2 in 13.61s\n",
      "‚úÖ IndicParlerTTS warm-up 2/2 in 11.18s\n"
     ]
    }
   ],
   "source": [
    "# 7Ô∏è‚É£ IndicParlerTTS Warm-up\n",
    "try:\n",
    "    for i in range(2):\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Dummy inputs\n",
    "        desc_input = description_tokenizer(\n",
    "            \"The voice is monotone and very fast in delivery, with clear audio and no background noise.\",\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        prompt_input = tokenizer(\n",
    "            \"‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ\",  # \"Hello world\" in Hindi\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        # Inference warm-up\n",
    "        with torch.no_grad():\n",
    "            audio_out = model.generate(\n",
    "                input_ids=desc_input.input_ids,\n",
    "                attention_mask=desc_input.attention_mask,\n",
    "                prompt_input_ids=prompt_input.input_ids,\n",
    "                prompt_attention_mask=prompt_input.attention_mask\n",
    "            )\n",
    "\n",
    "        # Optionally write to file for first time\n",
    "        if i == 0:\n",
    "            sf.write(\"warmup_output.wav\", audio_out.cpu().numpy().squeeze(), model.config.sampling_rate)\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(f\"‚úÖ IndicParlerTTS warm-up {i+1}/2 in {t1-t0:.2f}s\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è IndicParlerTTS warm-up failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f57519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Recording (4s)‚Ä¶\n",
      "‚úÖ Filtered audio saved: input.wav\n",
      "üåê Detected Language Code: te\n",
      "üåê Interpreted as: Telugu\n",
      "üåê Detected Language Code: te\n",
      "üåê Interpreted as: Telugu\n",
      "üõ§Ô∏è Routing to IndicConformer for Telugu...\n",
      "üìù IndicConformer Transcription: ‡∞à ‡∞∞‡±ã‡∞ú‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡∞æ‡∞ï‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞∏‡∞Ç‡∞§‡±ã‡∞∑‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø\n",
      "üó£Ô∏è Attempt 1/2: Speak target language name (e.g., Tamil, Hindi, German)\n",
      "üé§ Recording (1.7s)‚Ä¶\n",
      "‚úÖ Filtered audio saved: target_attempt_1.wav\n",
      "üìù You said: English.\n",
      "‚úÖ Interpreted as: English\n",
      "\n",
      "üîç Phase-Wise Latency Report:\n",
      " ‚Ä¢ record              : 4.39 sec\n",
      " ‚Ä¢ lang_detect         : 3.23 sec\n",
      " ‚Ä¢ asr                 : 1.83 sec\n",
      " ‚Ä¢ target_lang_select  : 7.88 sec\n",
      " ‚Ä¢ translation         : 12.39 sec\n",
      " ‚Ä¢ tts                 : 3.44 sec\n",
      " ‚Ä¢ Lang‚ÜíTTS Pipeline   : 23.95 sec\n",
      " ‚Ä¢ Total Runtime       : 35.87 sec\n",
      "\n",
      "üßæ Language & Routing Info:\n",
      " ‚Ä¢ Source Language        : Telugu (te)\n",
      " ‚Ä¢ Target Language        : english (en)\n",
      " ‚Ä¢ Model Routed Through   : IndicConformer\n",
      "\n",
      "üß† Transcription ‚Üí Translation:\n",
      " ‚Ä¢ ASR Output             : ‡∞à ‡∞∞‡±ã‡∞ú‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡∞æ‡∞ï‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞∏‡∞Ç‡∞§‡±ã‡∞∑‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø\n",
      " ‚Ä¢ Translation Output     : Today is a very good day. I am very happy.\n",
      "\n",
      "üñ•Ô∏è System Info:\n",
      " ‚Ä¢ CPU                 : arm\n",
      " ‚Ä¢ Cores               : 8\n",
      " ‚Ä¢ RAM_GB              : 8.59\n",
      " ‚Ä¢ Platform            : Darwin 24.5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2025-06-29T20:43:23.698318',\n",
       " 'record': 4.3927346669952385,\n",
       " 'lang_detect': 3.226943042012863,\n",
       " 'asr': 1.8286797089967877,\n",
       " 'target_lang_select': 7.879896083002677,\n",
       " 'translation': 12.394115333008813,\n",
       " 'tts': 3.4372319579997566,\n",
       " 'pipeline_core_latency': 23.95,\n",
       " 'total_runtime': 35.87,\n",
       " 'source_language': 'Telugu (te)',\n",
       " 'model_routed': 'IndicConformer',\n",
       " 'transcription': '‡∞à ‡∞∞‡±ã‡∞ú‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞Æ‡∞Ç‡∞ö‡∞ø ‡∞∞‡±ã‡∞ú‡±Å ‡∞®‡∞æ‡∞ï‡±Å ‡∞ö‡∞æ‡∞≤‡∞æ ‡∞∏‡∞Ç‡∞§‡±ã‡∞∑‡∞Ç‡∞ó‡∞æ ‡∞â‡∞Ç‡∞¶‡∞ø',\n",
       " 'target_language': 'english (en)',\n",
       " 'translated_text': 'Today is a very good day. I am very happy.',\n",
       " 'CPU': 'arm',\n",
       " 'Cores': 8,\n",
       " 'RAM_GB': 8.59,\n",
       " 'Platform': 'Darwin 24.5.0'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "def optimized_voice_to_voice(duration=4, log_file=\"/Users/srivighnateja/Desktop/Speech-text/asr_evaluation_log.json\"):\n",
    "    torch.set_num_threads(8)\n",
    "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "    timings = {}\n",
    "    profiling = {}\n",
    "    start_all = perf_counter()\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 1: Start Beep + Record ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    play_beep()\n",
    "    t0 = perf_counter()\n",
    "    audio_path = record_audio(duration=duration, filename=\"input.wav\", playback=False)\n",
    "    t1 = perf_counter()\n",
    "    timings['record'] = t1 - t0\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 2: Language Detection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    t0 = perf_counter()\n",
    "    src_code, src_lang, is_indic = detect_input_language_whisper(audio_path, whisper_model)\n",
    "    t1 = perf_counter()\n",
    "    timings['lang_detect'] = t1 - t0\n",
    "    profiling['source_language'] = f\"{src_lang} ({src_code})\"\n",
    "    profiling['model_routed'] = 'IndicConformer' if is_indic else 'Whisper'\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 3: Transcription (ASR) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    t0 = perf_counter()\n",
    "    transcription = transcribe_audio(audio_path, whisper_model)\n",
    "    t1 = perf_counter()\n",
    "    timings['asr'] = t1 - t0\n",
    "    profiling['transcription'] = transcription\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ Fine-grained: Time from LangID ‚Üí TTS Playback ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    langid_to_tts_start = perf_counter()\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 4: Target Language Detection ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    play_beep()\n",
    "    t0 = perf_counter()\n",
    "    tgt_code, tgt_lang = detect_target_language_by_voice()\n",
    "    if not tgt_code:\n",
    "        tgt_code, tgt_lang = detect_target_language_manually()\n",
    "    t1 = perf_counter()\n",
    "    timings['target_lang_select'] = t1 - t0\n",
    "    profiling['target_language'] = f\"{tgt_lang} ({tgt_code})\"\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 5: Translation ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    t0 = perf_counter()\n",
    "    translated_text = translate_with_nllb(transcription, src_code, tgt_code)\n",
    "    t1 = perf_counter()\n",
    "    timings['translation'] = t1 - t0\n",
    "    profiling['translated_text'] = translated_text\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ PHASE 6: TTS Synthesis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    t0 = perf_counter()\n",
    "    if tgt_code in indian_languages:\n",
    "        desc = description_tokenizer(\"The voice is monotone and very fast in delivery, with clear audio and no background noise.\", return_tensors=\"pt\").to(device)\n",
    "        prompt = tokenizer(translated_text, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            audio_arr = model.generate(\n",
    "                input_ids=desc.input_ids,\n",
    "                attention_mask=desc.attention_mask,\n",
    "                prompt_input_ids=prompt.input_ids,\n",
    "                prompt_attention_mask=prompt.attention_mask\n",
    "            ).cpu().numpy().squeeze()\n",
    "        sf.write(\"output.wav\", audio_arr, model.config.sampling_rate)\n",
    "        t1 = perf_counter()\n",
    "        playsound(\"output.wav\")\n",
    "    else:\n",
    "        engine.say(translated_text)\n",
    "        engine.runAndWait()\n",
    "    t1 = perf_counter()\n",
    "    timings['tts'] = t1 - t0\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ Final Metrics ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    total_runtime = perf_counter() - start_all\n",
    "    langid_to_tts_total = perf_counter() - langid_to_tts_start\n",
    "    system = {\n",
    "        \"CPU\": platform.processor(),\n",
    "        \"Cores\": psutil.cpu_count(logical=False),\n",
    "        \"RAM_GB\": round(psutil.virtual_memory().total / 1e9, 2),\n",
    "        \"Platform\": platform.system() + \" \" + platform.release()\n",
    "    }\n",
    "\n",
    "    entry = {\n",
    "        \"timestamp\": datetime.datetime.now().isoformat(),\n",
    "        **timings,\n",
    "        \"pipeline_core_latency\": round(langid_to_tts_total, 2),\n",
    "        \"total_runtime\": round(total_runtime, 2),\n",
    "        **profiling,\n",
    "        **system\n",
    "    }\n",
    "\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{entry}\\n\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ REPORTING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    print(\"\\nüîç Phase-Wise Latency Report:\")\n",
    "    for phase, t in timings.items():\n",
    "        print(f\" ‚Ä¢ {phase:20s}: {t:.2f} sec\")\n",
    "    print(f\" ‚Ä¢ {'Lang‚ÜíTTS Pipeline':20s}: {langid_to_tts_total:.2f} sec\")\n",
    "    print(f\" ‚Ä¢ {'Total Runtime':20s}: {total_runtime:.2f} sec\")\n",
    "\n",
    "    print(\"\\nüßæ Language & Routing Info:\")\n",
    "    print(f\" ‚Ä¢ Source Language        : {profiling['source_language']}\")\n",
    "    print(f\" ‚Ä¢ Target Language        : {profiling['target_language']}\")\n",
    "    print(f\" ‚Ä¢ Model Routed Through   : {profiling['model_routed']}\")\n",
    "\n",
    "    print(\"\\nüß† Transcription ‚Üí Translation:\")\n",
    "    print(f\" ‚Ä¢ ASR Output             : {transcription}\")\n",
    "    print(f\" ‚Ä¢ Translation Output     : {translated_text}\")\n",
    "\n",
    "    print(\"\\nüñ•Ô∏è System Info:\")\n",
    "    for k, v in system.items():\n",
    "        print(f\" ‚Ä¢ {k:20s}: {v}\")\n",
    "\n",
    "    return entry\n",
    "\n",
    "# ‚ñ∂Ô∏è Run it:\n",
    "optimized_voice_to_voice(duration=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
